# Benchmark

> 性能评测结果将在此处发布。

## 计划中的评测

- **工具调用准确率** — 不同模型在工具选择和参数填充上的准确率
- **RAG 检索质量** — 不同向量库和 Embedding 模型的检索效果对比
- **多智能体协作效率** — Team 模式下任务完成质量和 token 消耗
- **延迟与吞吐** — 流式 / 非流式场景下的响应延迟

## 评测框架

评测代码位于 `evaluation/` 目录，使用标准化的测试集和评分方法。

```bash
# 运行评测（待补充）
python -m evaluation.run --suite all
```

---

*此页面将持续更新评测结果。*
